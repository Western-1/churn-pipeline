# ğŸ“˜ Customer Churn Prediction Pipeline

![Python](https://img.shields.io/badge/Python-3.10-blue?logo=python&logoColor=white)
![Docker](https://img.shields.io/badge/Docker-Containerized-2496ED?logo=docker&logoColor=white)
![Airflow](https://img.shields.io/badge/Airflow-Orchestration-017CEE?logo=apacheairflow&logoColor=white)
![MLflow](https://img.shields.io/badge/MLflow-Tracking-0194E2?logo=mlflow&logoColor=white)
![MinIO](https://img.shields.io/badge/MinIO-S3_Storage-c72c48?logo=minio&logoColor=white)
![XGBoost](https://img.shields.io/badge/XGBoost-Model-EB0000?logo=xgboost&logoColor=white)
![Evidently](https://img.shields.io/badge/Evidently-Data_Validation-4B0082?logo=data&logoColor=white)
![PostgreSQL](https://img.shields.io/badge/PostgreSQL-Database-336791?logo=postgresql&logoColor=white)

## ğŸ’¡ TL;DR â€” What this is

**Customer Churn Prediction Pipeline** is a production-grade MLOps system capable of data validation, model training, experiment tracking, and artifact storage using a containerized microservices architecture.

It automates the lifecycle of a classification model (XGBoost) to predict whether a customer will leave a service, ensuring high data quality via Evidently AI and full reproducibility via MLflow.

---

## ğŸ“‚ Repository Layout
```
Churn_Prediction_Pipeline/
â”œâ”€â”€ dags/
â”‚   â””â”€â”€ churn_training_pipeline.py  # Airflow DAG definition
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                        # Raw input data
â”‚   â””â”€â”€ reports/                    # Generated drift reports
â”œâ”€â”€ docker/                         # Container configurations
â”‚   â”œâ”€â”€ airflow/
â”‚   â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”‚   â””â”€â”€ requirements.txt
â”‚   â””â”€â”€ mlflow/
â”‚       â””â”€â”€ Dockerfile
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ train.py                    # Training logic & MLflow logging
â”‚   â””â”€â”€ validate.py                 # Data validation logic (Evidently)
â”œâ”€â”€ .env                            # Environment variables
â”œâ”€â”€ .gitignore
â”œâ”€â”€ docker-compose.yml              # Multi-service infrastructure
â””â”€â”€ README.md                       # This file
```

---

## ğŸ’» Tech Stack

### Core Components

- ğŸ **Python 3.10** - Main runtime
- ğŸ¤– **XGBoost** - Classification algorithm
- ğŸ“Š **Pandas & Scikit-learn** - Data processing

### MLOps Infrastructure

- ğŸš€ **Apache Airflow** - Workflow orchestration
- ğŸ“ˆ **MLflow** - Experiment tracking & Model Registry
- ğŸ“¦ **MinIO** - S3-compatible artifact storage
- ğŸ›¡ï¸ **Evidently AI** - Data drift detection & validation
- ğŸ³ **Docker Compose** - Multi-container orchestration
- ğŸ˜ **PostgreSQL** - Backend for Airflow & MLflow metadata

---

## ğŸ§  How It Works

### 1. Pipeline Orchestration (Airflow)

The entire workflow is managed by Apache Airflow. The DAG handles dependencies between data validation and model training tasks.

![Airflow DAG](images/Airflow.png)
*Figure 1: Airflow DAG execution graph (Data Validation â†’ Model Training)*

### 2. Experiment Tracking (MLflow)

Model parameters, metrics, and metadata are automatically logged to the MLflow Server.

- **Algorithm:** XGBoost Classifier
- **Current Accuracy:** 80.62%
- **ROC AUC:** 0.8555

![MLflow UI](images/mlflow.png)
*Figure 2: MLflow UI displaying run metrics and parameters*

### 3. Artifact Storage (MinIO)

MinIO securely stores the serialized model (`model.pkl`), environment dependencies, and artifacts.

![MinIO Browser](images/MinIO.png)
*Figure 3: MinIO bucket structure showing saved artifacts*

---

## âš¡ Quickstart

### Prerequisites

- Docker & Docker Compose
- Git

### Start Infrastructure
```bash
# 1. Clone repository
git clone <repo-url>
cd Churn_Prediction_Pipeline

# 2. Build and start services
docker compose up -d --build

# 3. Check status
docker ps
```

### Fast Links

| Service | URL | Credentials (Default) |
|---------|-----|----------------------|
| **Airflow** | [http://localhost:8080](http://localhost:8080) | `airflow` / `airflow` |
| **MLflow** | [http://localhost:5000](http://localhost:5000) | None |
| **MinIO Console** | [http://localhost:9001](http://localhost:9001) | `minioadmin` / `minioadmin` |

---

## ğŸ› ï¸ Make / Docker Commands

If you need to manage the lifecycle manually:
```bash
# Stop all services
docker compose down

# Stop and remove volumes (Clean slate)
docker compose down --volumes

# Rebuild specific service
docker compose up -d --build airflow

# View logs
docker compose logs -f airflow
```

---

## ğŸ”“ License

MIT License

Copyright (c) 2026 Andriy Vlonha

Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.

---

## ğŸ“ Contact

ğŸ“§ **Email**: andriy.vlonha.dev@gmail.com