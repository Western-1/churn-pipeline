# ğŸ“˜ Customer Churn Prediction Pipeline
[![Scheduled Tests](https://github.com/Western-1/churn-pipeline/actions/workflows/scheduled.yml/badge.svg)](https://github.com/Western-1/churn-pipeline/actions/workflows/scheduled.yml)
[![CD Pipeline](https://github.com/Western-1/churn-pipeline/actions/workflows/cd.yml/badge.svg)](https://github.com/Western-1/churn-pipeline/actions/workflows/cd.yml)
[![CI Pipeline](https://github.com/Western-1/churn-pipeline/actions/workflows/ci.yml/badge.svg)](https://github.com/Western-1/churn-pipeline/actions/workflows/ci.yml)
![CI/CD](https://github.com/Western-1/churn-pipeline/actions/workflows/ci.yml/badge.svg)
![Python](https://img.shields.io/badge/Python-3.10-blue?logo=python&logoColor=white)
![Docker](https://img.shields.io/badge/Docker-Containerized-2496ED?logo=docker&logoColor=white)
![Airflow](https://img.shields.io/badge/Airflow-Orchestration-017CEE?logo=apacheairflow&logoColor=white)
![MLflow](https://img.shields.io/badge/MLflow-Tracking-0194E2?logo=mlflow&logoColor=white)
![MinIO](https://img.shields.io/badge/MinIO-S3_Storage-c72c48?logo=minio&logoColor=white)
![XGBoost](https://img.shields.io/badge/XGBoost-Model-EB0000?logo=xgboost&logoColor=white)
![Evidently](https://img.shields.io/badge/Evidently-Data_Validation-4B0082?logo=data&logoColor=white)
![PostgreSQL](https://img.shields.io/badge/PostgreSQL-Database-336791?logo=postgresql&logoColor=white)
![FastAPI](https://img.shields.io/badge/FastAPI-Web_Service-009688?logo=fastapi&logoColor=white)
![DVC](https://img.shields.io/badge/DVC-Data_Version_Control-945DD6?logo=dvc&logoColor=white)
![Prometheus](https://img.shields.io/badge/Prometheus-Monitoring-E6522C?logo=prometheus&logoColor=white)
![Grafana](https://img.shields.io/badge/Grafana-Visualization-F46800?logo=grafana&logoColor=white)
[![codecov](https://codecov.io/gh/Western-1/churn-pipeline/branch/main/graph/badge.svg)](https://codecov.io/gh/Western-1/churn-pipeline)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

## ğŸ’¡ TL;DR â€” What this is

**Customer Churn Prediction Pipeline** is a **production-grade MLOps system** featuring:

âœ… **Data Validation** with Evidently AI
âœ… **Experiment Tracking** with MLflow
âœ… **Workflow Orchestration** with Apache Airflow
âœ… **Data Versioning** with DVC
âœ… **Model Serving** via FastAPI
âœ… **Monitoring** with Prometheus & Grafana
âœ… **CI/CD** with GitHub Actions
âœ… **Containerization** with Docker Compose
âœ… **Automated Testing** with pytest (65%+ coverage)

It predicts customer churn using XGBoost, ensuring high data quality, reproducibility, and continuous monitoring in production.


> [!NOTE]
> Dataset: The model is trained on the Telco Customer Churn dataset from Kaggle, containing 7043 rows of customer data with 21 features including tenure, contract type, and monthly charges.

---

## ğŸ“‚ Repository Layout

```
churn-pipeline/
â”œâ”€â”€ .github/ scheduled.yml
â”‚   â””â”€â”€ workflows/
â”‚       â”œâ”€â”€ ci.yml                  # CI/CD pipeline
â”‚       â”œâ”€â”€ cd.yml                  # Deployment pipeline
â”‚       â””â”€â”€ tests.yml               # Scheduled tests
â”œâ”€â”€ airflow/
â”‚   â””â”€â”€ dags/
â”‚       â”œâ”€â”€ churn_training_pipeline.py
â”‚       â””â”€â”€ monitoring_dag.py
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                        # Raw input data (DVC tracked)
â”‚   â”œâ”€â”€ processed/                  # Processed datasets
â”‚   â””â”€â”€ reports/                    # Drift & validation reports
â”œâ”€â”€ docker/
â”‚   â”œâ”€â”€ airflow/
â”‚   â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”‚   â””â”€â”€ requirements.txt
â”‚   â”œâ”€â”€ mlflow/
â”‚   â”‚   â””â”€â”€ Dockerfile
â”‚   â””â”€â”€ inference/
â”‚       â””â”€â”€ Dockerfile
â”œâ”€â”€ monitoring/
â”‚   â”œâ”€â”€ docker-compose.monitoring.yml
â”‚   â”œâ”€â”€ prometheus.yml
â”‚   â”œâ”€â”€ alerts.yml
â”‚   â”œâ”€â”€ alertmanager.yml
â”‚   â””â”€â”€ grafana/
â”‚       â”œâ”€â”€ provisioning/
â”‚       â””â”€â”€ dashboards/
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ prepare_data.py
â”‚   â”œâ”€â”€ evaluate.py
â”‚   â””â”€â”€ setup_dvc.sh
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                   # Centralized configuration
â”‚   â”œâ”€â”€ feature_engineering.py      # Feature transformers
â”‚   â”œâ”€â”€ monitoring.py               # Prometheus metrics
â”‚   â”œâ”€â”€ utils.py                    # Utility functions
â”‚   â”œâ”€â”€ train.py                    # Training logic
â”‚   â”œâ”€â”€ validate.py                 # Data validation
â”‚   â””â”€â”€ inference.py                # FastAPI service
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ conftest.py
â”‚   â”œâ”€â”€ unit/
â”‚   â”‚   â”œâ”€â”€ test_data_validation.py
â”‚   â”‚   â”œâ”€â”€ test_feature_engineering.py
â”‚   â”‚   â”œâ”€â”€ test_model_training.py
â”‚   â”‚   â””â”€â”€ test_inference.py
â”‚   â””â”€â”€ integration/
â”‚       â”œâ”€â”€ test_airflow_dag.py
â”‚       â”œâ”€â”€ test_mlflow_tracking.py
â”‚       â””â”€â”€ test_api_endpoints.py
â”œâ”€â”€ .pre-commit-config.yaml
â”œâ”€â”€ dvc.yaml                        # DVC pipeline definition
â”œâ”€â”€ params.yaml                     # Training parameters
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ Makefile                        # Automation commands
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ’» Tech Stack

### ğŸ¯ Core ML Components
- **Python 3.10** - Main runtime
- **XGBoost** - Classification algorithm
- **Scikit-learn** - ML utilities
- **Pandas** - Data processing

### ğŸš€ MLOps Infrastructure
- **Apache Airflow** - Workflow orchestration
- **MLflow** - Experiment tracking & Model Registry
- **DVC** - Data version control
- **MinIO** - S3-compatible artifact storage
- **Evidently AI** - Data drift & quality monitoring
- **FastAPI** - REST API for inference
- **Docker Compose** - Multi-container orchestration
- **PostgreSQL** - Backend for Airflow & MLflow

### ğŸ“Š Monitoring & Observability
- **Prometheus** - Metrics collection
- **Grafana** - Visualization & dashboards
- **AlertManager** - Alert routing

### ğŸ§ª Testing & CI/CD
- **pytest** - Testing framework
- **GitHub Actions** - CI/CD pipelines
- **pre-commit** - Git hooks
- **codecov** - Coverage reporting
- **Black, isort, Flake8, MyPy** - Code quality

---

## ğŸ§  How It Works

### ğŸ“Š Model Performance

| Metric | Value | Status |
|--------|-------|--------|
| **Accuracy** | 80.62% | âœ… |
| **Precision** | 78.5% | âœ… |
| **Recall** | 82.1% | âœ… |
| **F1-Score** | 80.3% | âœ… |
| **ROC-AUC** | 85.55% | âœ… |

### ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Data Source   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  DVC + MinIO    â”‚â—„â”€â”€â”€â”€â”€â”¤ Data Version â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚   Control    â”‚
         â”‚               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Evidently     â”‚â”€â”€â–º Data Validation
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Airflow      â”‚â”€â”€â–º Orchestration
â”‚   (DAG Runner)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   XGBoost       â”‚â”€â”€â”€â”€â”€â”€â”¤    MLflow    â”‚
â”‚   Training      â”‚      â”‚   Tracking   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Model Registry â”‚
â”‚  (Production)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  FastAPI Server â”‚â—„â”€â”€â”€â”€â”€â”¤ Prometheus + â”‚
â”‚   (Inference)   â”‚      â”‚   Grafana    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1. ğŸš€ Pipeline Orchestration (Airflow)

The entire workflow is managed by Apache Airflow with smart branching based on model performance:

![Airflow DAG](images/Airflow.png)
*Figure 1: Airflow DAG execution graph (Data Validation â†’ Training â†’ Deployment)*

### ğŸ¥ Pipeline Demo

https://github.com/user-attachments/assets/50109779-18c8-4fd4-ba51-23c469f466a8

**Pipeline Steps:**
1. **Data Validation** - Evidently checks for drift & quality
2. **Feature Engineering** - Transform & create features
3. **Model Training** - Train XGBoost classifier
4. **Evaluation** - Calculate performance metrics
5. **MLflow Logging** - Track experiment
6. **Deployment Decision** - Branch based on performance
7. **Model Registration** - Register to MLflow Model Registry
8. **Production Deployment** - Transition to production stage

### 2. ğŸ“ˆ Experiment Tracking (MLflow)

All experiments are automatically tracked with full reproducibility:

![MLflow UI](images/mlflow_2_8_1.png)
*Figure 2: MLflow UI displaying run metrics and parameters*

**Tracked Components:**
- Hyperparameters (max_depth, learning_rate, etc.)
- Metrics (accuracy, precision, recall, AUC)
- Model artifacts
- Feature engineering pipelines
- Training datasets (via DVC)

### 3. ğŸ—‚ï¸ Data Versioning (DVC + MinIO)

DVC ensures data reproducibility by tracking datasets in MinIO:

![DVC Storage](images/dvc-storage.png)
*Figure 3: MinIO bucket `dvc-storage` with versioned datasets*

**Benefits:**
- âœ… Lightweight Git repository
- âœ… Every commit links to exact data version
- âœ… Team collaboration on large datasets
- âœ… Reproducible experiments

### 4. ğŸ“¦ Artifact Storage (MinIO)

All models and artifacts are stored in S3-compatible MinIO:

![MinIO Browser](images/MinIO.png)
*Figure 4: MinIO bucket structure*

### 5. ğŸ”® Model Serving (FastAPI)

Production-ready REST API with auto-documentation:

![Swagger UI](images/Predict_answer.png)
*Figure 5: FastAPI Swagger UI with prediction example*

**Features:**
- âš¡ Async request handling
- ğŸ“Š Prometheus metrics
- ğŸ”„ Auto-reload on model updates
- ğŸ“ OpenAPI documentation
- âœ… Input validation with Pydantic

**Example Request:**
```bash
curl -X POST http://localhost:8000/predict \
  -H "Content-Type: application/json" \
  -d '{
    "gender": "Female",
    "SeniorCitizen": 0,
    "Partner": "Yes",
    "tenure": 12,
    "MonthlyCharges": 29.85,
    "TotalCharges": 358.2
    # ... other fields
  }'
```

**Response:**
```json
{
  "churn_prediction": 1,
  "probability": 0.73,
  "message": "Customer will CHURN ğŸ”´",
  "model_version": "v1.2.3"
}
```

### ğŸ” Operational Endpoints (Screenshots)

<details>
<summary><b>Click to expand API capability screenshots</b></summary>

| Endpoint | Description | Screenshot |
|----------|-------------|------------|
| **/health** | System health check & model status | ![Health Check](images/health.png) |
| **/metrics** | Prometheus metrics exposition | ![Metrics](images/metrics.png) |
| **/feedback** | Ground truth feedback loop | ![Feedback](images/feedback.png) |

</details>

### 6. ğŸ“Š Monitoring & Alerting

Real-time monitoring with Prometheus & Grafana:

**Grafana Dashboard:**
![Grafana Dashboard](images/Grafana_full_load_test.png)
*Figure 6: Grafana dashboard visualizing system load, latency, and model metrics*

**Prometheus Targets:**
![Prometheus Targets](images/Prometheus_targets.png)
*Figure 7: Prometheus actively scraping metrics from Inference Service and Node Exporter*

**Grafana Dashboard includes:**
- ğŸ“ˆ Predictions per hour
- â±ï¸ Prediction latency (p95, p99)
- ğŸ¯ Model accuracy & AUC trends
- ğŸš¨ Data drift detection
- âš ï¸ Error rate monitoring
- ğŸ’¾ System resource usage

**Alerts configured for:**
- Model accuracy degradation (< 75%)
- Data drift detection
- High prediction latency (> 1s)
- API downtime

---

## âš¡ Quickstart

### Prerequisites

- Docker & Docker Compose
- Git
- Python 3.10+ (for local development)

### ğŸš€ Full Setup (5 minutes)

```bash
# 1. Clone repository
git clone https://github.com/Western-1/churn-pipeline.git
cd churn-pipeline

# 2. Copy environment variables
cp .env.example .env

# 3. Start all services
make docker-up

# 4. Setup DVC (optional, for data versioning)
make dvc-setup

# 5. Check services status
make docker-ps
```
> [!TIP]
> If you encounter No space left on device, run docker system prune -a." "Ensure ports 8080, 5000, and 3000 are free.


### ğŸ”‘ Configuration (.env)
```bash
# ------------------------------
# ğŸ—„ï¸ Database (PostgreSQL)
# ------------------------------
POSTGRES_USER=airflow
POSTGRES_PASSWORD=airflow
POSTGRES_DB=airflow
POSTGRES_HOST=postgres
POSTGRES_PORT=5432

# ------------------------------
# â˜ï¸ MinIO (S3 Object Storage)
# ------------------------------
MINIO_ENDPOINT=localhost:9000
MINIO_ACCESS_KEY=minioadmin
MINIO_SECRET_KEY=minioadmin

# ------------------------------
# ğŸ§ª MLflow Tracking & Artifacts
# ------------------------------
MLFLOW_TRACKING_URI=http://localhost:5000
# S3 Connection for MLflow (accessed via boto3)
AWS_ACCESS_KEY_ID=minioadmin
AWS_SECRET_ACCESS_KEY=minioadmin
AWS_DEFAULT_REGION=us-east-1
MLFLOW_S3_ENDPOINT_URL=http://localhost:9000

# ------------------------------
# ğŸŒ¬ï¸ Airflow System
# ------------------------------
# Required for Linux/WSL to fix permission issues
AIRFLOW_UID=1000
```

### ğŸ”— Access Points

| Service | URL | Credentials |
|---------|-----|-------------|
| **Inference API** | http://localhost:8000/docs | None |
| **Airflow** | http://localhost:8080 | `airflow` / `airflow` |
| **MLflow** | http://localhost:5000 | None |
| **MinIO Console** | http://localhost:9001 | `minioadmin` / `minioadmin` |
| **Grafana** | http://localhost:3000 | `admin` / `admin` |
| **Prometheus** | http://localhost:9090 | None |

---

## ğŸ› ï¸ Development Workflow

### Running Tests

```bash
# All tests with coverage
make test

# Unit tests only
make test-unit

# Integration tests only
make test-integration

# View coverage report
open htmlcov/index.html
```

### Code Quality

```bash
# Run all linters
make lint

# Auto-format code
make format

# Run pre-commit hooks
make pre-commit-run
```
![Pre-commit](images/pre-commit_console.png)

### Training Pipeline

```bash
# Run full DVC pipeline
make train

# Show metrics
make metrics

# Compare experiments
make compare

# View plots
make plots
```

### Local API Development

```bash
# Run API with hot-reload
make api-run

# Test endpoint
make api-test
```

### Monitoring

```bash
# Start monitoring stack
make monitoring-up

# View Grafana dashboards
# Navigate to http://localhost:3000

# Stop monitoring
make monitoring-down
```

---

## ğŸ“Š CI/CD Pipeline

### Automated Checks (on every push)

âœ… Code linting (Black, Flake8, MyPy)
âœ… Unit & integration tests
âœ… Docker build validation
âœ… Security scanning (Trivy, Bandit)
âœ… Coverage reporting (Codecov)

### Deployment (on tags)

```bash
# Create release
git tag -a v1.0.0 -m "Release v1.0.0"
git push origin v1.0.0

# Automated actions:
# 1. Build & push Docker images to GHCR
# 2. Deploy to staging
# 3. Run smoke tests
# 4. Deploy to production (manual approval)
# 5. Create GitHub release
```

---

## ğŸ“– Documentation

- [API Reference](http://localhost:8000/docs)

---

## ğŸ§ª Testing Coverage

| Module | Coverage | Status |
|--------|----------|--------|
| **src/validate.py** | 92% | âœ… |
| **src/feature_engineering.py** | 88% | âœ… |
| **src/train.py** | 85% | âœ… |
| **src/inference.py** | 94% | âœ… |
| **src/monitoring.py** | 90% | âœ… |
| **Overall** | **89%** | âœ… |

---

## ğŸš§ Roadmap

### âœ… Completed
- [x] Core ML pipeline with XGBoost
- [x] Airflow orchestration
- [x] MLflow tracking
- [x] DVC data versioning
- [x] FastAPI inference
- [x] Prometheus monitoring
- [x] Grafana dashboards
- [x] CI/CD with GitHub Actions
- [x] Comprehensive testing (89% coverage)
- [x] Docker containerization

### ğŸ”„ In Progress
- [ ] Kubernetes deployment (Helm charts)
- [ ] A/B testing framework
- [ ] Real-time streaming with Kafka
- [ ] Advanced feature store

---

## ğŸ¤ Contributing

Welcome contributions!

### Development Setup

```bash
# Install dependencies
make install-dev

# Setup pre-commit hooks
pre-commit install

# Run local CI checks
make ci-local
```

---

## ğŸ“ License

MIT License - see [LICENSE](LICENSE) file for details.

Copyright (c) 2026 Andriy Vlonha

---

## ğŸ“ Contact

**Andriy Vlonha**
ğŸ“§ Email: [andriy.vlonha.dev@gmail.com](mailto:andriy.vlonha.dev@gmail.com)
ğŸ’¼ LinkedIn: [Andriy Vlonha](https://www.linkedin.com/in/Ğ°Ğ½Ğ´Ñ€Ñ–Ğ¹-Ğ²Ğ»Ğ¾Ğ½Ğ³Ğ°-9562b537b)
ğŸ™ GitHub: [@Western-1](https://github.com/Western-1)
ğŸ“± Telegram: [@Westerny](https://t.me/Westerny)

---

## ğŸ™ Acknowledgments

Built with:
- [Apache Airflow](https://airflow.apache.org/)
- [MLflow](https://mlflow.org/)
- [FastAPI](https://fastapi.tiangolo.com/)
- [DVC](https://dvc.org/)
- [Evidently AI](https://www.evidentlyai.com/)
- [XGBoost](https://xgboost.readthedocs.io/)
- [Prometheus](https://prometheus.io/)
- [Grafana](https://grafana.com/)

---

<p align="center">
  <b>â­ Star this repo if you find it useful!</b><br>
  Made with â¤ï¸ by <a href="https://github.com/Western-1">Andriy Vlonha</a>
</p>
